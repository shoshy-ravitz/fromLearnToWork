{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.2:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [21/Mar/2025 02:45:14] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:45:41] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:46:04] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "[2025-03-21 02:47:29,414] ERROR in app: Exception on /upload_resume [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user1\\AppData\\Roaming\\Python\\Python311\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Roaming\\Python\\Python311\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Roaming\\Python\\Python311\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Roaming\\Python\\Python311\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Roaming\\Python\\Python311\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_28988\\1725174057.py\", line 215, in upload_resume\n",
      "    os.remove(temp_path)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'temp_resume.pdf'\n",
      "127.0.0.1 - - [21/Mar/2025 02:47:29] \"POST /upload_resume HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:47:34] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:04] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:06] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:08] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:14] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:17] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:20] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:31] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:34] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 02:48:36] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:05:18] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:06:57] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:06:59] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:07:02] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:07:20] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:07:23] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:07:26] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:09:02] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:09:04] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2025 03:09:06] \"POST /check_answer HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# import base64\n",
    "# import os\n",
    "# from flask import Flask, request, jsonify\n",
    "# from flask_cors import CORS\n",
    "# from dotenv import load_dotenv\n",
    "# from google import genai\n",
    "# from google.genai import types\n",
    "\n",
    "# load_dotenv()\n",
    "# gemini_api_key = os.getenv('GEMINI_API_KEY', 'AIzaSyA1_-pRQQz89muAzUCFH1AFPDxyNkG5ctI')\n",
    "\n",
    "\n",
    "# app = Flask(__name__)\n",
    "# CORS(app)\n",
    "\n",
    "# def encode_file_to_base64(file_path):\n",
    "#     \"\"\" ממיר קובץ לבסיס 64 \"\"\"\n",
    "#     with open(file_path, \"rb\") as file:\n",
    "#         return base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "# def analyze_resume(resume_file_path):\n",
    "#     client = genai.Client(api_key=gemini_api_key)\n",
    "#     model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "#     encoded_resume = encode_file_to_base64(resume_file_path)\n",
    "\n",
    "#     prompt = \"נתח את קובץ קורות החיים המצורף וספק רשימה של 10 שאלות על הידיעות בחומר שיש בקורות חיים.\"\n",
    "   \n",
    "#     contents = [\n",
    "#         types.Content(\n",
    "#             role=\"user\",\n",
    "#             parts=[\n",
    "#                 types.Part(text=prompt),\n",
    "#                 types.Part(\n",
    "#                     inline_data=types.Blob(\n",
    "#                         mime_type=\"application/pdf\",  # או mime type אחר בהתאם לקובץ\n",
    "#                         data=encoded_resume,\n",
    "#                     )\n",
    "#                 ),\n",
    "#             ],\n",
    "#         ),\n",
    "#     ]\n",
    "\n",
    "#     generate_content_config = types.GenerateContentConfig(\n",
    "#         temperature=1,\n",
    "#         top_p=0.95,\n",
    "#         top_k=40,\n",
    "#         max_output_tokens=8192,\n",
    "#         response_mime_type=\"application/json\",\n",
    "#     )\n",
    "\n",
    "#     response_text = \"\"\n",
    "#     for chunk in client.models.generate_content_stream(\n",
    "#         model=model, contents=contents, config=generate_content_config\n",
    "#     ):\n",
    "#         response_text += chunk.text\n",
    "\n",
    "#     return response_text\n",
    "\n",
    "# @app.route(\"/upload_resume\", methods=[\"POST\"])\n",
    "# def upload_resume():\n",
    "    \n",
    "#     if \"resume\" not in request.files:\n",
    "#         return jsonify({\"error\": \"No resume file provided\"}), 400\n",
    "   \n",
    "#     resume_file = request.files[\"resume\"]\n",
    "#     temp_path = \"temp_resume.pdf\"  # או כל סיומת אחרת\n",
    "#     resume_file.save(temp_path)\n",
    "   \n",
    "#     try:\n",
    "#         analysis_result = analyze_resume(temp_path)\n",
    "#         return jsonify({\"questions\": analysis_result}), 200\n",
    "#     except Exception as e:\n",
    "#         return jsonify({\"error\": str(e)}), 500\n",
    "#     finally:\n",
    "#         os.remove(temp_path)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)\n",
    "import base64\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY', 'AIzaSyA1_-pRQQz89muAzUCFH1AFPDxyNkG5ctI')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def encode_file_to_base64(file_path):\n",
    "    \"\"\" ממיר קובץ לבסיס 64 \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "def analyze_resume(resume_file_path):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    encoded_resume = encode_file_to_base64(resume_file_path)\n",
    "\n",
    "    prompt = \"נתח את קובץ קורות החיים המצורף וספק רשימה של 10 שאלות על הידיעות בחומר שיש בקורות חיים.\"\n",
    "   \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(\n",
    "                        mime_type=\"application/pdf\",\n",
    "                        data=encoded_resume,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=8192,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "\n",
    "def check_answer_with_gamini(question, answer):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    prompt = f\" האם התשובה לשאלה '{question}' נכונה? התשובה היא: '{answer}'.\"\n",
    "    \n",
    "    # כאן תוכל להוסיף הנחיות לגבי ציון התשובה\n",
    "    prompt += \" תן לי ציון על התשובה בין 0 ל-10, כאשר 10 זה תשובה נכונה לחלוטין.\"\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    prompt = f\" האם התשובה לשאלה '{question}' נכונה? התשובה היא: '{answer}'.\"\n",
    "   \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "\n",
    "@app.route(\"/upload_resume\", methods=[\"POST\"])\n",
    "def upload_resume():\n",
    "    if \"resume\" not in request.files:\n",
    "        return jsonify({\"error\": \"No resume file provided\"}), 400\n",
    "   \n",
    "    resume_file = request.files[\"resume\"]\n",
    "    temp_path = \"temp_resume.pdf\"\n",
    "    resume_file.save(temp_path)\n",
    "   \n",
    "    try:\n",
    "        analysis_result = analyze_resume(temp_path)\n",
    "        return jsonify({\"questions\": analysis_result}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "    finally:\n",
    "        os.remove(temp_path)\n",
    "\n",
    "@app.route(\"/check_answer\", methods=[\"POST\"])\n",
    "def check_answer():\n",
    "    data = request.json\n",
    "    question = data.get('question')\n",
    "    answer = data.get('answer')\n",
    "    \n",
    "    if not question or not answer:\n",
    "        return jsonify({\"error\": \"Question and answer must be provided\"}), 400\n",
    "\n",
    "    feedback = check_answer_with_gamini(question, answer)\n",
    "    # הנחה היא שהפידבק כולל גם ציון, לדוגמה: \"תשובה נכונה. ציון: 10\"\n",
    "    \n",
    "    return jsonify({\"feedback\": feedback}), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
